{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMMc7xZuDYBh43w/J6MN6bM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HLokeshwari/ArtificialNeuralNetwork/blob/main/SIXTH.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5vty88z_i2mR",
        "outputId": "c7526fb2-0c77-4d44-8b77-f2081415251c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting scikeras\n",
            "  Downloading scikeras-0.13.0-py3-none-any.whl.metadata (3.1 kB)\n",
            "Requirement already satisfied: keras>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from scikeras) (3.8.0)\n",
            "Requirement already satisfied: scikit-learn>=1.4.2 in /usr/local/lib/python3.11/dist-packages (from scikeras) (1.6.1)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from keras>=3.2.0->scikeras) (1.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from keras>=3.2.0->scikeras) (1.26.4)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.2.0->scikeras) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.2.0->scikeras) (0.0.8)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.11/dist-packages (from keras>=3.2.0->scikeras) (3.12.1)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.2.0->scikeras) (0.14.0)\n",
            "Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.11/dist-packages (from keras>=3.2.0->scikeras) (0.4.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from keras>=3.2.0->scikeras) (24.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.4.2->scikeras) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.4.2->scikeras) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.4.2->scikeras) (3.5.0)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from optree->keras>=3.2.0->scikeras) (4.12.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.2.0->scikeras) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.2.0->scikeras) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->scikeras) (0.1.2)\n",
            "Downloading scikeras-0.13.0-py3-none-any.whl (26 kB)\n",
            "Installing collected packages: scikeras\n",
            "Successfully installed scikeras-0.13.0\n"
          ]
        }
      ],
      "source": [
        "pip install scikeras"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install imbalanced-learn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AQEffAVXkklM",
        "outputId": "a6e6c628-7a4d-48c6-f043-02a8a9ee274f"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: imbalanced-learn in /usr/local/lib/python3.11/dist-packages (0.13.0)\n",
            "Requirement already satisfied: numpy<3,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from imbalanced-learn) (1.26.4)\n",
            "Requirement already satisfied: scipy<2,>=1.10.1 in /usr/local/lib/python3.11/dist-packages (from imbalanced-learn) (1.13.1)\n",
            "Requirement already satisfied: scikit-learn<2,>=1.3.2 in /usr/local/lib/python3.11/dist-packages (from imbalanced-learn) (1.6.1)\n",
            "Requirement already satisfied: sklearn-compat<1,>=0.1 in /usr/local/lib/python3.11/dist-packages (from imbalanced-learn) (0.1.3)\n",
            "Requirement already satisfied: joblib<2,>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from imbalanced-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl<4,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from imbalanced-learn) (3.5.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, StratifiedShuffleSplit\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers, Input\n",
        "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
        "from scikeras.wrappers import KerasClassifier\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "# 1. Data Pre-processing\n",
        "df = pd.read_csv('churn.csv')  # Replace 'churn.csv' with your actual file path\n",
        "\n",
        "# Convert 'churn' to numerical (0 and 1)\n",
        "df['churn'] = df['churn'].apply(lambda x: 0 if x == 'FALSE' else 1)\n",
        "\n",
        "# Handle categorical features (excluding phone number)\n",
        "categorical_cols = df.select_dtypes(include='object').columns\n",
        "for col in categorical_cols:\n",
        "    if col != 'phone number':\n",
        "        le = LabelEncoder()\n",
        "        df[col] = le.fit_transform(df[col])\n",
        "\n",
        "# Drop 'phone number'\n",
        "df = df.drop('phone number', axis=1)\n",
        "\n",
        "# Separate features (X) and target (y)\n",
        "X = df.drop('churn', axis=1)\n",
        "y = df['churn']\n",
        "\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# Improved Train/Test Split with StratifiedShuffleSplit and class check\n",
        "# ------------------------------------------------------------------------------\n",
        "\n",
        "while True:  # Loop until we get both classes in training set\n",
        "    splitter = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
        "    for train_index, test_index in splitter.split(X, y):\n",
        "        X_train_initial, X_test = X.iloc[train_index], X.iloc[test_index]\n",
        "        y_train_initial, y_test = y.iloc[train_index], y.iloc[test_index]\n",
        "\n",
        "    if len(y_train_initial.unique()) > 1:  # Check for both classes\n",
        "        break  # Exit the loop if both classes are present\n",
        "\n",
        "print(\"y_train_initial value counts:\\n\", y_train_initial.value_counts())  # Verify\n",
        "print(\"y_test value counts:\\n\", y_test.value_counts())\n",
        "\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# Address class imbalance using SMOTE (if needed)\n",
        "# ------------------------------------------------------------------------------\n",
        "smote = SMOTE(random_state=42)\n",
        "X_train, y_train = smote.fit_resample(X_train_initial, y_train_initial)\n",
        "\n",
        "# Scale numerical features using StandardScaler\n",
        "numerical_cols = X_train.select_dtypes(include=np.number).columns\n",
        "scaler = StandardScaler()\n",
        "X_train[numerical_cols] = scaler.fit_transform(X_train[numerical_cols])\n",
        "X_test[numerical_cols] = scaler.transform(X_test[numerical_cols])\n",
        "\n",
        "\n",
        "# 2. Neural Network Architecture\n",
        "def create_model(neurons1=64, neurons2=32, dropout1=0.2, dropout2=0.1, learning_rate=0.001):\n",
        "    model = keras.Sequential([\n",
        "        Input(shape=(X_train.shape[1],)),\n",
        "        layers.Dense(neurons1, activation='relu'),\n",
        "        layers.Dropout(dropout1),\n",
        "        layers.Dense(neurons2, activation='relu'),\n",
        "        layers.Dropout(dropout2),\n",
        "        layers.Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "    optimizer = keras.optimizers.Adam(learning_rate=learning_rate)\n",
        "    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "model = create_model()\n",
        "history = model.fit(X_train, y_train, epochs=50, batch_size=32, validation_split=0.1, verbose=0)\n",
        "\n",
        "loss, accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(f\"Test Loss: {loss}\")\n",
        "print(f\"Test Accuracy: {accuracy}\")\n",
        "\n",
        "y_pred_proba = model.predict(X_test, verbose=0)\n",
        "y_pred = (y_pred_proba > 0.5).astype(int)\n",
        "\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(classification_report(y_test, y_pred))\n",
        "print(f\"Accuracy Score: {accuracy_score(y_test, y_pred)}\")\n",
        "\n",
        "\n",
        "# 3. Hyperparameter Tuning\n",
        "model_cv = KerasClassifier(model=create_model, verbose=0)\n",
        "\n",
        "param_grid = {\n",
        "    'neurons1': [32, 64, 128],\n",
        "    'neurons2': [16, 32, 64],\n",
        "    'dropout1': [0.1, 0.2, 0.3],\n",
        "    'dropout2': [0.1, 0.2],\n",
        "    'learning_rate': [0.001, 0.01, 0.1],\n",
        "    'epochs': [30, 50],\n",
        "    'batch_size': [16, 32]\n",
        "}\n",
        "\n",
        "grid = GridSearchCV(estimator=model_cv, param_grid=param_grid, cv=3, verbose=1, scoring='accuracy')\n",
        "grid_result = grid.fit(X_train, y_train)\n",
        "\n",
        "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
        "\n",
        "best_model = grid_result.best_estimator_.model\n",
        "y_pred_tuned = best_model.predict(X_test, verbose=0)\n",
        "y_pred_tuned = (y_pred_tuned > 0.5).astype(int)\n",
        "\n",
        "print(confusion_matrix(y_test, y_pred_tuned))\n",
        "print(classification_report(y_test, y_pred_tuned))\n",
        "print(f\"Tuned Model Accuracy Score: {accuracy_score(y_test, y_pred_tuned)}\")"
      ],
      "metadata": {
        "id": "9t0ldL4hmi0N"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}